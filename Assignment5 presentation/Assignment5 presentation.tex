\documentclass{beamer}
\usepackage{listings}
\lstset{
%language=C,
frame=single, 
breaklines=true,
columns=fullflexible
}
\usepackage{blkarray}
\usepackage{subcaption}
\usepackage{url}
\usepackage{tikz}
\usepackage{tkz-euclide} % loads  TikZ and tkz-base
%\usetkzobj{all}
\usetikzlibrary{calc,math}
\usepackage{float}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\renewcommand{\vec}[1]{\mathbf{#1}}
\usepackage[export]{adjustbox}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{tikz}
\usetikzlibrary{automata, positioning}
\usetheme{Boadilla}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}

\title{UGC/MATH (2018 Dec-Math set-a ) Q.104}
\author{Lanka Prasanna}
\date{CS20BTECH11029}
\begin{document}

\begin{frame}
\titlepage
\end{frame}
\begin{frame}{Topics covered}
\begin{block}{Prerequisites:}
\begin{enumerate}[]
\item Chi-square distribution
\item Weak law of large numbers with its proof
\item Strong law of large numbers
\item Almost sure convergence
\item Central limit theorem
\item Properties of mean and variance
\end{enumerate}
\end{block}
\begin{block}{UGC NET problem}
\begin{enumerate}[]
 \item Question
\item Solution 
\end{enumerate}
\end{block}


\end{frame}
\begin{frame}
\frametitle{}
\begin{block}{Chi-square distribution}
If $X_1,X_2,\cdots$ are independent normally distributed random variables with mean 0 and variance 1. Then $\chi=X_{1}^2+X_{2}^2+\cdots+X_{n}^2$ is chi-square distributed with $n$ degrees of freedom.
\begin{align}
    E(\chi)=n \label{eq:x2}
\end{align}
\begin{align}
    Var(\chi)=2n\label{eq:x10}
\end{align}\label{lem}
\end{block}
\end{frame}

\begin{frame}
\frametitle{}
\begin{block}{Weak law of large numbers}

Let $X_1,X_2,\cdots $ be i.i.d random variables with same expectation($\mu$) and finite variance($\sigma^2$).Let $S_{n}=X_1+X_2+\cdots X_n$,Then as $n \to \infty$
\begin{align}
    \frac{S_n}{n} \xrightarrow{i.p}  \mu,
\end{align}
in probability
\end{block}
\textbf{Proof:}\\
Define a new variable
\begin{align}
    X \equiv \frac{X_1+X_2+\cdots X_n}{n}
\end{align}
\end{frame}
\begin{frame}

Then, as $n \to \infty$
\begin{align}
    E(X)&=E\left(\frac{X_1+X_2+\cdots X_n}{n}\right)\\
    &=\frac{E(X_1)+\cdots E(X_n)}{n}\\
    &=\frac{n \mu}{n}\\
    &=\mu
\end{align}
In addition,
\begin{align}
    Var(X)&=Var\left(\frac{X_1+X_2+\cdots X_n}{n}\right)\\
    &=Var\left(\frac{X_1}{n}\right)+\cdots Var\left(\frac{X_n}{n}\right)\\
    &=\frac{n\sigma^2}{n^2}\\
    &=\frac{\sigma^2}{n}
\end{align}
\end{frame}
\begin{frame}
Therefore, by Chebyshev inequality, for all $\epsilon>0$,
\begin{align}
   \pr{|X-\mu| \geq \epsilon} \leq \frac{Var(X)}{\epsilon^2}=\frac{\sigma^2}{n\epsilon^2}   
\end{align}
As $n \to \infty$, it follows that
\begin{align}
    \lim_{n \to \infty} \pr{|X-\mu| \geq \epsilon}=0
\end{align}
Stated other way as $n \to \infty$
\begin{align}
    \frac{S_n}{n} \xrightarrow{i.p}  \mu,
\end{align}
in probability


\end{frame}

\begin{frame}
\frametitle{}
\begin{block}{Strong law of large numbers}
Let $X_1,X_2,\cdots $ be i.i.d random variables with same expectation($\mu$) and finite variance($\sigma^2$).Let $S_{n}=X_1+X_2+\cdots X_n$,Then as $n \to \infty$
\begin{align}
    \frac{S_n}{n} \xrightarrow{a.s}  \mu,
\end{align}
almost surely.
\end{block}

\frametitle{}
\begin{block}{Almost sure convergence}
A sequence of random variables $X_n$ where $n\in N$ is said to converge almost surely or with probability 1 (denoted by a.s or w.p 1) to X if \label{with prob 1}
\begin{align}
    \pr{\omega |X_n(\omega) \to X(\omega)}=1
\end{align}
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{Central limit theorem}
The Central limit theorem states that the distribution of the sample approximates a normal distribution as the sample size becomes larger,given that all the samples are equal in size,regardless of the distribution of the individual samples.
\end{block}    
\end{frame}

\begin{frame}
\frametitle{}
\begin{block}{Properties of mean and variance}
If $X$ is a random variable with a probability density function of $f(x)$. If $a$ and $b$ are constants.
\begin{align}
    \label{1}
    E(X)&=\int_R xf(x)dx\\ 
    \label{2}
    E(X+Y)&=E(X)+E(Y)\\    
    \label{3}
    E(aX+b)&=aE(X)+b, \\   
    \label{4}
    Var(X)&=E(X^2)-{E(X)}^2\\  
    \label{5}
    Var(X+Y)&=Var(X)+Var(Y)\\  
    \label{6}
    Var(aX+b)&=a^2 Var(X)
\end{align}
\end{block}
\end{frame}



\begin{frame}
\frametitle{Question}
\begin{block}{ UGC/MATH (2018 Dec-Math set-a ) Q.104}
Let $X_1,X_2, \cdots$ be i.i.d. $N(0,1)$ random variables. Let $S_{n}=X_{1}^2+X_{2}^2+\cdots+X_{n}^2.\forall n\geq 1. $Which of the following statements are correct?
\begin{enumerate}[(A)]
\setlength\itemsep{1em}
\item $\frac{S_{n}-n}{\sqrt{2}}\sim N(0,1)$ for all $n\geq 1$
\item For all $\epsilon > 0$,$\pr{\brak{\left|{\frac{S_n}{n}-2}\right|>\epsilon}}\to 0$ as $n \to \infty$
\item $\frac{S_{n}}{n} \to 1$ with probability 1
\item $\pr{S_n \leq n+ \sqrt{n}x} \rightarrow \pr{Y \leq x} \forall x \in R$ ,where $Y \sim N(0,2)$
\end{enumerate}
\end{block}
\end{frame}

\begin{frame}
\frametitle{Solution}
Given $X_1,X_2, \cdots$ follow normal distribution with mean 0 and variance 1.
\begin{align}
    f_{X_i}(x)=\frac{1}{\sqrt{2}\pi}e^{-\frac{x^2}{2}} ,i \in \cbrak{1,2,\cdots}
\end{align}

 \end{frame}

\begin{frame}
\frametitle{Option A}
From definition of chi-square distribution $S_n$ is a chi-distributed function with $n$ degrees of freedom.\\
From \eqref{eq:x2} 
\begin{align}
    E(S_n)=n \label{eq:8}
\end{align}
From \eqref{eq:8} and \eqref{3}
\begin{align}
    E\left(\frac{S_{n}-n}{\sqrt{2}}\right)&=\frac{E(S_n)-n}{\sqrt{2}}\\
     &=\frac{n-n}{\sqrt{2}}\\
    &=0
\end{align}
From \eqref{eq:x10}
\begin{align}
    Var(S_n)= 2n\label{var}
\end{align}
\end{frame}
\begin{frame}{Option A contd.}
From \eqref{var} and \eqref{6}

\begin{align}
    Var\left(\frac{S_{n}-n}{\sqrt{2}}\right)
    &= Var\left(\frac{S_n}{\sqrt{2}}\right)\\
    &=\frac{Var(S_n)}{2}\\
    &=\frac{2n}{2}\\
    &=n
\end{align}

Hence, from central limit theorem
\begin{align}
    \left(\frac{S_{n}-n}{\sqrt{2}}\right)\sim N(0,n)
\end{align}
Hence \textbf{Option A is false.}
\end{frame}



\begin{frame}
\frametitle{Option B}
Given 
\begin{align}
    S_{n}=X_{1}^2+X_{2}^2+\cdots+X_{n}^2.\forall n\geq 1
\end{align}
Assume that For all $\epsilon > 0$,$\pr{\brak{\left|{\frac{S_n}{n}-2}\right|>\epsilon}}\to 0$ as $n \to \infty$ is true

Let
\begin{align}
    X \equiv \frac{X_{1}^2+X_{2}^2+\cdots X_{n}^2}{n}
\end{align}
From \eqref{eq:8} and \eqref{3}
\begin{align}
    E(X)&=E\left(\frac{S_n}{n}\right)\\
        &=\frac{E(S_n)}{n}\\
        &=\frac{n}{n}\\
        &=1\label{25}
\end{align}
\end{frame}


\begin{frame}{Option B contd.}
From weak law of large numbers
\begin{align}
    \frac{S_n}{n} \xrightarrow{i.p}  E\left(\frac{S_n}{n}\right)
\end{align}

\begin{align}
    \lim_{n \to \infty} \pr{\left|{\frac{S_n}{n}-1}\right|>\epsilon}=0
\end{align}
This means for all $\epsilon>0$ ,$\pr{\left|{\frac{S_n}{n}-1}\right|>\epsilon}\to 0$ as $n \to \infty$

But this is contradiction to our assumption.\\
Hence \textbf{Option B is false .}


    
\end{frame}
\begin{frame}{Option C}
   Given 
\begin{align}
    S_{n}=X_{1}^2+X_{2}^2+\cdots+X_{n}^2.\forall n\geq 1
\end{align}
Hence from Strong law of large numbers we can write 
\begin{align}
    \frac{S_n}{n} \xrightarrow{a.s} E\left(\frac{S_n}{n}\right)
\end{align}
From \eqref{25}
\begin{align}
     \frac{S_n}{n} \xrightarrow{a.s} 1
\end{align}
almost surely.
\begin{align}
    \pr{\lim_{n\to \infty}\frac{S_n}{n}=1}=1\label{eq:27}
\end{align}
\end{frame}

\begin{frame}{Option C contd.}

From definition of Almost sure convergence and \eqref{eq:27} we can write,
\begin{align}
    \frac{S_{n}}{n} \xrightarrow{w.p.1} 1
\end{align}
with probability 1.\\
Hence \textbf{Option C is true}.


\end{frame}



\begin{frame}{Option D}
Let 
\begin{align}
    Y=\frac{S_{n}-n}{\sqrt{n}}
\end{align}
Using \eqref{eq:8} and \eqref{3}
\begin{align}
    E\left(\frac{S_{n}-n}{\sqrt{n}}\right)&=\frac{E(S_n)-n}{\sqrt{n}}\\
    &=\frac{n-n}{\sqrt{n}}\\
    &=0
\end{align}
using \eqref{eq:8} and \eqref{3}
\begin{align}
     Var\left(\frac{S_{n}-n}{\sqrt{n}}\right)&=\frac{Var(S_n)}{n}\\
     &=\frac{2n}{n}\\
     &=2
\end{align}
\end{frame}
\begin{frame}{Option D contd.}
Hence, from central limit theorem
\begin{align}
    Y \sim N(0,2)\label{eq:D}
\end{align}

\begin{align}
     \pr{\frac{S_{n}-n}{\sqrt{n}} \leq x}= \pr{S_{n} \leq n+\sqrt{n}x}
\end{align}
Therefore,
\begin{align}
   \pr{S_n \leq n+ \sqrt{n}x} \rightarrow \pr{Y \leq x} \forall x \in R \label{new}
\end{align}
Hence, \textbf{Option D is true.}
    
\end{frame}


\end{document}